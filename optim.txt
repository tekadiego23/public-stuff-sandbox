import os
from collections import defaultdict
from concurrent.futures import ThreadPoolExecutor, as_completed

import requests
from requests.auth import HTTPBasicAuth
from urllib3.util.retry import Retry
from requests.adapters import HTTPAdapter


# --- client HTTP réutilisable (une seule fois) --------------------------------
def make_session(total_retries=5, backoff_factor=2, timeout=10, pool_maxsize=100):
    retry = Retry(
        total=total_retries,
        backoff_factor=backoff_factor,
        status_forcelist=[500, 502, 503, 504],
        allowed_methods=["GET", "POST"],
        raise_on_status=False,
    )
    adapter = HTTPAdapter(max_retries=retry, pool_connections=pool_maxsize, pool_maxsize=pool_maxsize)

    s = requests.Session()
    s.headers.update({"accept": "application/json", "Content-Type": "application/json"})
    s.mount("https://", adapter)
    s.mount("http://", adapter)
    # on stocke quelques trucs utiles
    s._timeout = timeout
    s._auth = HTTPBasicAuth(os.getenv("AIRFLOW_USERNAME"), os.getenv("AIRFLOW_PASSWORD"))
    return s


# --- lecture portfolio avec cache mémoire -------------------------------------
def fetch_portfolio_detail(session: requests.Session, base_url: str, portfolio_id: str):
    """
    Appelle l’API pour 1 portfolio.
    base_url est du style 'https://.../portfolio/' ; on concatène l'id.
    """
    url = f"{base_url}{portfolio_id}"
    r = session.get(url, auth=session._auth, timeout=session._timeout, verify=False)
    r.raise_for_status()
    return r.json()


def prefetch_portfolios(session, base_url, portfolio_ids, max_workers=16):
    """
    Précharge en parallèle les détails des portfolios uniques.
    Retourne un dict {portfolio_id: json}
    """
    results = {}
    # petite limite pour ne pas saturer l’API si la liste est énorme
    if max_workers and max_workers > 1:
        with ThreadPoolExecutor(max_workers=max_workers) as ex:
            fut2id = {ex.submit(fetch_portfolio_detail, session, base_url, pid): pid for pid in portfolio_ids}
            for fut in as_completed(fut2id):
                pid = fut2id[fut]
                try:
                    results[pid] = fut.result()
                except Exception as e:
                    # à vous d’adapter: on log et on continue, ou on remonte l’erreur
                    results[pid] = {}  # ou None
    else:
        for pid in portfolio_ids:
            results[pid] = fetch_portfolio_detail(session, base_url, pid)
    return results


def group_positions_by_instrument(positions, pf_detail_base_url, max_workers=16):
    """
    Optimisé:
    1) on collecte tous les portfolio_id uniques
    2) on précharge leurs détails (cache)
    3) on groupe les positions, en réutilisant le cache
    """
    session = make_session()

    # 1) collecter les portfolios uniques + préparer la structure de sortie
    portfolio_ids = set()
    grouped = defaultdict(lambda: {"epi": [], "hmsBook": "", "legalEntity": "", "desk": ""})

    for position in positions:
        for product in position.get("products", []):
            product_id = product.get("id", {}).get("sophis")
            if not product_id:
                continue
            pos_id = position.get("id", {}).get("hpi") or position.get("id")  # robustesse
            pf_id = position.get("portfolioId", {}).get("sophis")
            if pf_id:
                portfolio_ids.add(pf_id)
            # on crée déjà le conteneur pour ne pas refaire des vérifs plus tard
            _ = grouped[product_id]["epi"]  # force la clé

    # 2) précharger les détails des portfolios (une seule fois par id)
    portfolio_cache = prefetch_portfolios(session, pf_detail_base_url, portfolio_ids, max_workers=max_workers)

    # 3) remplir les infos et l’index des positions
    for position in positions:
        for product in position.get("products", []):
            product_id = product.get("id", {}).get("sophis")
            if not product_id:
                continue
            pos_id = position.get("id", {}).get("hpi") or position.get("id")
            pf_id = position.get("portfolioId", {}).get("sophis")

            grouped[product_id]["epi"].append(pos_id)

            if pf_id:
                pf_detail = portfolio_cache.get(pf_id, {})
                if "hmsBook" in pf_detail and pf_detail["hmsBook"]:
                    grouped[product_id]["hmsBook"] = pf_detail["hmsBook"]
                if "legalEntity" in pf_detail and pf_detail["legalEntity"]:
                    grouped[product_id]["legalEntity"] = pf_detail["legalEntity"]
                if "desk" in pf_detail and pf_detail["desk"]:
                    grouped[product_id]["desk"] = pf_detail["desk"]

    return dict(grouped)
