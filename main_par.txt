# eqs/main.py
import os
from concurrent.futures import ThreadPoolExecutor
from fastapi import FastAPI
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

from eqs.pricer import Pricer  # adapte l'import

async def lifespan(app: FastAPI):
    # 1) Pricer (et sa session) créés une seule fois
    pricer = Pricer(eqphoenix_env=os.getenv("PHOENIX_ENV", "prod"))
    session = pricer.client.session  # <-- on garde ta session

    # 2) Connexion pool & retries (thread-safe côté urllib3)
    adapter = HTTPAdapter(
        pool_connections=200,   # connexions partagées
        pool_maxsize=200,       # concurrente max
        max_retries=Retry(
            total=2, backoff_factor=0.1,
            status_forcelist=(429, 500, 502, 503, 504),
            allowed_methods=False,  # garde POST
        ),
    )
    session.mount("http://", adapter)
    session.mount("https://", adapter)

    app.state.pricer = pricer

    # 3) Thread pool pour exécuter le code **bloquant**
    max_workers = int(os.getenv("THREAD_POOL_SIZE", "64"))
    app.state.tpool = ThreadPoolExecutor(max_workers=max_workers)

    yield

    app.state.tpool.shutdown(wait=True)

app = FastAPI(lifespan=lifespan)
# ... tes routers ...





import asyncio
from fastapi import Request
from fastapi.responses import JSONResponse

@router.post("/pricing-request")
async def pricing_request(
    request: Request,
    reqJson: eqs.apis.models.PricingRequestBody,
    trace_id: str | None = Header(default=None),
):
    app = request.app
    loop = asyncio.get_running_loop()

    # SLA dur à 10 s (couvre TOUT, y compris tes appels pricer)
    try:
        # Passe ce dont ton code sync a besoin (pricer, etc.)
        result: JSONResponse = await asyncio.wait_for(
            loop.run_in_executor(
                app.state.tpool,
                forward_post_request_sync_wrapper,  # petite fonction ci-dessous
                app.state.pricer, reqJson, RequestType.pricingRequest
            ),
            timeout=10.0,
        )
        return result
    except asyncio.TimeoutError:
        return JSONResponse(status_code=504, content={"message": "SLA 10s exceeded"})




# eqs/apis/requests_apis.py (ou common.py)
def forward_post_request_sync_wrapper(pricer, reqJson, requestType):
    # -> tu peux conserver forward_post_request tel quel et juste lui passer pricer
    # Si aujourd’hui forward_post_request instancie son propre Pricer,
    # ajoute un param optionnel et utilise celui du lifespan s’il est fourni.

    return forward_post_request(pricer, reqJson, requestType)



# extrait à l’endroit des appels HTTP existants
# AVANT : response = pricer.client.session.post(req_url, json=reqJson.model_dump())
# APRES :
response = pricer.client.session.post(
    req_url,
    json=reqJson.model_dump(),
    timeout=(2, 8),   # 2s connect, 8s read -> total < 10s
)

# AVANT : r = pricer.client.session.get(resp_url, params=..., )
# APRES :
r = pricer.client.session.get(
    resp_url,
    params={"phoenix_job_id": job_id},
    timeout=(2, 8),
)
