# eqs/main.py
import os
from concurrent.futures import ThreadPoolExecutor
from fastapi import FastAPI
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

# === adapte ces imports à ton projet ===
from eqs.pricer import Pricer
from eqs.apis.common import forward_post_request, forward_get_request
from eqs.apis.requests_apis import router as requests_router


def _configure_session(session):
    """
    Configure la requests.Session pour du trafic concurrent:
    - pool de connexions partagé
    - retries idempotents (inclut POST via allowed_methods=False)
    """
    adapter = HTTPAdapter(
        pool_connections=200,
        pool_maxsize=200,
        max_retries=Retry(
            total=2,
            backoff_factor=0.1,
            status_forcelist=(429, 500, 502, 503, 504),
            allowed_methods=False,  # laisse passer POST
        ),
    )
    session.mount("http://", adapter)
    session.mount("https://", adapter)
    return session


def _get_or_create_pricer(app: FastAPI, phoenix_env: str) -> Pricer:
    """
    Cache de Pricer par phoenix_env, pour réutiliser la même Session (keep-alive).
    """
    cache = app.state.pricer_cache
    if phoenix_env in cache:
        return cache[phoenix_env]
    p = Pricer(phoenix_env)
    _configure_session(p.client.session)
    cache[phoenix_env] = p
    return p


async def lifespan(app: FastAPI):
    # Thread pool pour exécuter le code sync (Pricer + requests.Session)
    app.state.tpool = ThreadPoolExecutor(
        max_workers=int(os.getenv("THREAD_POOL_SIZE", "64"))
    )
    # Cache Pricer par env
    app.state.pricer_cache = {}
    # Fournisseurs injectés aux fonctions sync
    app.state.get_pricer = lambda env: _get_or_create_pricer(app, env)
    app.state.forward_post_request = forward_post_request
    app.state.forward_get_request = forward_get_request

    yield

    app.state.tpool.shutdown(wait=True)


app = FastAPI(lifespan=lifespan)

# tes routers
app.include_router(requests_router, tags=["Pricing"])
